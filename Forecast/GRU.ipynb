{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Dataset from Yahoo Finance\n",
    "\n",
    "**Common Tickers include: ['TSLA','FB','AMZN','GOOG','TWTR']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "stock_symbol = 'GOOG'\n",
    "data = yf.download(tickers=stock_symbol,period='2y',interval='1d')\n",
    "data = data.reset_index()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the Real Stock Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(data['Close'],color='black',label='true trend')\n",
    "plt.title('%s Stock Prices'%stock_symbol)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('%s Stock Prices'%stock_symbol)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marking a training timeframe of 60 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 60\n",
    "data_train = data[:-test_size]\n",
    "data_test = data[-test_size:]\n",
    "data.shape,data_train.shape,data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data_train.drop(['Date','Adj Close'],axis=1)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "training_data = scaler.fit_transform(training_data)\n",
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the training set\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(test_size, training_data.shape[0]):\n",
    "    x_train.append(training_data[i-test_size:i])\n",
    "    y_train.append(training_data[i,3])\n",
    "# last 60 days will be the training set - X\n",
    "# 61st day is the target value - Y\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparaing testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_test_days = data_train.tail(test_size)\n",
    "df = pd.concat([past_test_days,data_test])\n",
    "df = df.drop(['Date','Adj Close'],axis='columns')\n",
    "df.shape, df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scaler.transform(df)\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(test_size,df.shape[0]):\n",
    "    x_test.append(df[i-test_size:i])\n",
    "    y_test.append(df[i,3])\n",
    "\n",
    "x_test, y_test = np.array(x_test),np.array(y_test)\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Scaling Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below is the scaling label, \n",
    "# therefore we need to divide our y_pred with the below scaling value it used to scale the data\n",
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1/8.50296711e-04\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test*scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU - Gated Recurrent Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape[1],x_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st layer\n",
    "model.add(GRU(units=40,activation='relu',return_sequences=False, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast():\n",
    "    model.fit(x_train,y_train,epochs=300,batch_size=32)\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = y_pred*scale\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_forecast():\n",
    "    history = model.fit(x_train,y_train,epochs=300,batch_size=32)\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = y_pred*scale\n",
    "    return history,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_forecast = []\n",
    "simulation = 10\n",
    "print(\"Simulation 1\")\n",
    "history,first_result = first_forecast()\n",
    "result_forecast.append(first_result)\n",
    "for i in range(1,simulation):\n",
    "    print(\"Simulation %d\"%(i+1))\n",
    "    result_forecast.append(forecast())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the Accuracy using MAPE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE - Mean Absolute Percentage Error\n",
    "def calculate_accuracy(real, predict):\n",
    "    real = np.array(real) + 1\n",
    "    predict = np.array(predict) + 1\n",
    "    percentage = 1 - np.mean(np.abs((real-predict)/real))\n",
    "    return percentage * 100\n",
    "mean_accuracy = []\n",
    "for i in range(simulation):\n",
    "    mean_accuracy.append(calculate_accuracy(y_test, result_forecast[i]))\n",
    "\n",
    "mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE - Root Mean Squared Error \n",
    "def calculate_rmse(real, predict):\n",
    "    real = np.array(real) + 1\n",
    "    predict = np.array(predict) + 1\n",
    "    percentage = 1 - np.sqrt(np.mean(np.square((y_test - result_forecast[0])/y_test)))\n",
    "    return percentage * 100\n",
    "mean_rmse = []\n",
    "for i in range(simulation):\n",
    "    mean_rmse.append(calculate_rmse(y_test, result_forecast[i]))\n",
    "\n",
    "mean_rmse,np.mean(mean_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "for i in range(simulation):\n",
    "    plt.plot(result_forecast[i],label='forecast %d'%(i+1))\n",
    "plt.plot(y_test,color='black',label='true trend')\n",
    "plt.title('Mean Accuracy: %.4f'%np.mean(mean_accuracy))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('%s Stock Prices'%stock_symbol)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('GRU Model, Accuracy vs Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('GRU Model, Loss vs Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_test_set = data_test\n",
    "present_test_set = present_test_set.drop(['Date','Adj Close'],axis=1)\n",
    "\n",
    "#scale the data\n",
    "present_input = scaler.transform(present_test_set)\n",
    "\n",
    "# preparing the arrays according to the test_size\n",
    "present_test = []\n",
    "present_test.append(present_input)\n",
    "\n",
    "for i in range(1,test_size):\n",
    "    a = [0,0,0,0,0]\n",
    "    ar = []\n",
    "    for j in range(0,test_size):\n",
    "        ar.append(a)\n",
    "    present_test.append(ar)\n",
    "\n",
    "present_test = np.array(present_test)\n",
    "\n",
    "y = model.predict(present_test)\n",
    "predicted_value = y[0]*scale\n",
    "print(\"Next Day's Predicted Closing Index = %f\"%predicted_value[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Analysis\n",
    "\n",
    ">**Dataset:**\n",
    ">* GOOG\n",
    ">* 2y  \n",
    ">\n",
    ">**Training Timestamp:**\n",
    ">* 60 days\n",
    ">  \n",
    ">**Model:**\n",
    ">* 2 layers - (1 Input + 1 Output)\n",
    ">* GRU layer - activation = relu\n",
    ">* GRU layer - units = 40\n",
    ">* GRU layers - dropout = 0.2\n",
    ">* Dense layer - units = 1  \n",
    ">\n",
    ">**Compile:**\n",
    ">* optimizer = adam\n",
    ">\n",
    ">**Training:**\n",
    ">* epochs: 300\n",
    ">* batch_size = 32\n",
    ">\n",
    ">**Mean Accuracy:**\n",
    ">* MAPE - 91.11%\n",
    ">* RMSE - 86.01%\n",
    "\n",
    "**Predicted Closing Index for 26th March: 957.272522**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12fa7049ba81415d243121a7f1057ca3c8360c45ddf912c725b557457cc48376"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
